User-agent: *
Allow: /

# Sitemap
Sitemap: https://splitsave.app/sitemap.xml

# Crawl-delay for respectful crawling
Crawl-delay: 1

# Disallow private areas
Disallow: /api/
Disallow: /_next/
Disallow: /admin/
Disallow: /private/

# Allow important pages
Allow: /
Allow: /about
Allow: /features
Allow: /pricing
Allow: /contact
Allow: /blog
Allow: /help
Allow: /terms
Allow: /privacy

# Specific rules for search engines
User-agent: Googlebot
Allow: /
Crawl-delay: 0.5

User-agent: Bingbot
Allow: /
Crawl-delay: 1

User-agent: Slurp
Allow: /
Crawl-delay: 1

# Block AI training bots
User-agent: GPTBot
Disallow: /

User-agent: ChatGPT-User
Disallow: /

User-agent: CCBot
Disallow: /

User-agent: anthropic-ai
Disallow: /

User-agent: Claude-Web
Disallow: /

User-agent: Omgilibot
Disallow: /

# Block archive bots
User-agent: ia_archiver
Disallow: /

User-agent: archive.org_bot
Disallow: /

# Block social media bots (optional)
User-agent: facebookexternalhit
Disallow: /

User-agent: Twitterbot
Disallow: /

User-agent: LinkedInBot
Disallow: /

# Block analytics and monitoring bots
User-agent: AhrefsBot
Disallow: /

User-agent: SemrushBot
Disallow: /

User-agent: MJ12bot
Disallow: /

User-agent: DotBot
Disallow: /

User-agent: BLEXBot
Disallow: /

User-agent: Screaming Frog SEO Spider
Disallow: /

# Block security scanners
User-agent: Nessus
Disallow: /

User-agent: Acunetix
Disallow: /

User-agent: sqlmap
Disallow: /

User-agent: Nikto
Disallow: /

# Block other unwanted bots
User-agent: Baiduspider
Disallow: /

User-agent: YandexBot
Disallow: /

User-agent: Sogou
Disallow: /

User-agent: 360Spider
Disallow: /

# Rate limiting for all bots
User-agent: *
Crawl-delay: 2
